{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to create a video + audio pipeline using the GStreamer multimedia framework with two different source options:\n",
    "* The first option uses an encoded video file as source. This capture pipeline is based on ``multifilesrc`` and ``decodebin`` which demuxes the video and audio streams of the video file.\n",
    "* The second option captures video/audio from an incoming HDMI stream. This capture pipeline is based on ``mediasrcbin`` for video and ``alsasrc`` for audio.\n",
    "\n",
    "On the sink side, ``kmssink`` is used for video and ``alsasink`` for audio.\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Create a GStreamer pipeline that includes a video and audio path using the ``parse_launch()`` API\n",
    "2. Create a GStreamer pipeline graph and view it inside this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all python modules required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, clear_output\n",
    "import glob\n",
    "import subprocess\n",
    "import pydot\n",
    "import sys\n",
    "import gi\n",
    "import re\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import GObject, GLib, Gst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Base TRD notebook 4 (nb4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = \"nb8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for saving the pipeline graph as dot file. Set the GStreamer debug dot directory environment variable to point to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotdir = \"/home/root/gst-dot/\" + nb\n",
    "!mkdir -p $dotdir\n",
    "%env GST_DEBUG_DUMP_DOT_DIR = $dotdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the GStreamer library. Enable debug by setting the debug string, set default to level 1 for all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gst.init(None)\n",
    "Gst.debug_set_threshold_from_string('*:1', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create String Representation of GStreamer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the ``kmssink`` and ``alsasink`` elements and their properties as string representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_id = 38\n",
    "vsink = \"kmssink plane-id=\" + str(plane_id)\n",
    "asink = \"alsasink device=hw:0,0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``get_media_by_device`` function returns the matching media node for a given video capture source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_media_dev_by_name(src):\n",
    "    sources = {\n",
    "        'hdmi' : 'vcap_hdmi'\n",
    "    }\n",
    "    devices = glob.glob('/dev/media*')\n",
    "    for dev in devices:\n",
    "        proc = subprocess.run(['media-ctl', '-d', dev, '-p'], capture_output=True, encoding='utf8')\n",
    "        for line in proc.stdout.splitlines():\n",
    "            if sources[src] in line:\n",
    "                return dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``parse_media_dv_detect`` function parse the digital video (DV) timing detected on the incoming HDMI stream. It returns the width, height, and framerate of the detected stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_media_dv_detect(dev):\n",
    "    proc = subprocess.run(['media-ctl', '-d', dev, '-p'], capture_output=True, encoding='utf8')\n",
    "    for line in proc.stdout.splitlines():\n",
    "        if \"dv.detect\" in line:\n",
    "            m = re.match(r'.*\\s+(?P<w>\\d+)x(?P<h>\\d+)p(?P<f>\\d+)\\s+.*', line)\n",
    "            return m.group('w'), m.group('h'), m.group('f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a string representation of the pipeline by concatenating the individual element strings. The following sources are supported in this notebook:\n",
    "* ``file`` : video file playback\n",
    "* ``hdmi`` : HDMI input (platform3 only)\n",
    "\n",
    "If ``hdmi`` is selected as source, ``mediasrcbin`` is instantiated for the video input and ``alsasrc`` is instantiated for the audio input from HDMI Rx. The video input is sent to ``kmssink`` and the audio input is sent to ``alsasink``. Each path has a capsfilter: the video caps are determined by parsing the DV detect info of the incoming HDMI stream; the audio caps are hard-coded. **Note:** This option is only valid for platform3.\n",
    "\n",
    "If ``file`` is selected (default), the ``multifilesrc`` element in combination with ``decodebin`` is used to play back an encoded video file. Decodebin creates two src pads, one for video and one for audio which are dynamically connected to ``kmssink`` and ``alsasink`` respectively. The ``videoconvert`` and ``audioconvert`` elements are used to convert video and audio formats per the sinks' capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"file\" # change source to hdmi or file\n",
    "\n",
    "if source == \"hdmi\":\n",
    "    # get media device node\n",
    "    media_device = get_media_dev_by_name(source)\n",
    "    if media_device is None:\n",
    "        raise Exception('Unable to find video source ' + source + '. Make sure the device is plugged in, powered, and the correct platform is used.')\n",
    "    # parse dv detect string\n",
    "    width, height, fps = parse_media_dv_detect(media_device)\n",
    "    # create pipeline string\n",
    "    vsrc = \"mediasrcbin media-device=\" + media_device\n",
    "    vcaps = \"video/x-raw, width=\" + str(width) + \", height=\" + str(height) + \", format=YUY2, framerate=\" + fps + \"/1\"  \n",
    "    asrc = \"alsasrc device=hw:0,1\"\n",
    "    acaps = \"audio/x-raw, rate=48000, channels=2, format=S16LE\"\n",
    "    pipe = vsrc + \" ! \" + vcaps + \" ! queue max-size-bytes=0 ! \" + vsink + \" \" + asrc + \" ! \" + acaps + \" ! queue ! \" + asink\n",
    "else:\n",
    "    # create pipeline string\n",
    "    file_name = \"/usr/share/movies/Big_Buck_Bunny_4K.webm.360p.vp9.webm\"\n",
    "    src = \"multifilesrc loop=true location=\" + file_name\n",
    "    pipe = src + \" ! decodebin name=dec dec. ! videoconvert ! queue max-size-bytes=0 ! \" + vsink + \" dec. ! audioconvert ! queue ! \" + asink\n",
    "\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create and Run the GStreamer Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the string representations of the first and second pipeline as a single pipeline graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Gst.parse_launch(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``bus_call`` function listens on the bus for ``EOS`` and ``ERROR`` events. If any of these events occur, stop the pipeline (set to ``NULL`` state) and quit the main loop.\n",
    "\n",
    "In case of an ``ERROR`` event, parse and print the error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bus_call(bus, message, loop):\n",
    "    t = message.type\n",
    "    if t == Gst.MessageType.EOS:\n",
    "        sys.stdout.write(\"End-of-stream\\n\")\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    elif t == Gst.MessageType.ERROR:\n",
    "        err, debug = message.parse_error()\n",
    "        sys.stderr.write(\"Error: %s: %s\\n\" % (err, debug))\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline (set to ``PLAYING`` state), create the main loop and listen to messages on the bus. Register the ``bus_call`` callback function with the ``message`` signal of the bus. Start the main loop.\n",
    "\n",
    "The video will be displayed on the monitor. \n",
    "\n",
    "To stop the pipeline, click the square shaped icon labelled 'Interrupt the kernel' in the top menu bar. Create a dot graph of the pipeline topology before stopping the pipeline. Quit the main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_state(Gst.State.PLAYING);\n",
    "\n",
    "loop = GLib.MainLoop()\n",
    "bus = pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\", bus_call, loop)\n",
    "\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    Gst.debug_bin_to_dot_file(pipeline, Gst.DebugGraphDetails.ALL, nb)\n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. View the Pipeline dot Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register dot plugins for png export to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dot file to png and display the pipeline graph. The image will be displayed below the following code cell. Double click on the generate image file to zoom in.\n",
    "\n",
    "**Note:** This step may take a few seconds. Also, compared to previous notebooks, two disjoint graphs are displayed in the same image as we have created two parallel pipelines in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotfile = dotdir + \"/\" + nb + \".dot\"\n",
    "graph = pydot.graph_from_dot_file(dotfile, 'utf-8')\n",
    "display(Image(graph[0].create(None, 'png', 'utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you learned how to:\n",
    "1. Create a GStreamer pipeline that includes video and audio from a string representation using the ``parse_launch()`` API\n",
    "2. Export the pipeline topology as a dot file image and display it in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Copyright© 2019 Xilinx</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
