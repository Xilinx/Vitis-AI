{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to playback an encoded video file and display it inside this jupyter notebook using the GStreamer multimedia framework.\n",
    "\n",
    "The example video file used in this notebook is VP9 encoded (https://www.webmproject.org/vp9/) and uses the webm container format (https://www.webmproject.org/docs/container/).\n",
    "\n",
    "The video pipeline is composed of the following GStreamer elements:\n",
    "* The ``multifilesrc`` element is used to read the file from disk\n",
    "* The ``vp9dec`` and ``matroskademux`` elements are used to decode and demux the video file. The file encoding is auto-detected and the required element auto-instantiated by the ``decodebin`` element.\n",
    "* The ``videoconvert`` and ``jpegenc`` element are used to convert and compress the raw video format to JPEG.\n",
    "* The ``appsink`` element is used to make the JPEG frames available to the jupyter notebook where they are displayed.\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Create a GStreamer video pipeline that decodes a video file and displays the video inside this notebook.\n",
    "2. Create a GStreamer pipeline graph and view it inside this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all python modules required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, clear_output\n",
    "import pydot\n",
    "import sys\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "gi.require_version(\"GstApp\", \"1.0\")\n",
    "from gi.repository import GObject, GLib, Gst, GstApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Base TRD notebook 1 (nb1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = \"nb1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for saving the pipeline graph as dot file. Set the GStreamer debug dot directory environment variable to point to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotdir = \"/home/root/gst-dot/\" + nb\n",
    "!mkdir -p $dotdir\n",
    "%env GST_DEBUG_DUMP_DOT_DIR = $dotdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the GStreamer library. Enable debug by setting the debug string, set default to level 1 for all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gst.init(None)\n",
    "Gst.debug_set_threshold_from_string('*:1', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create and Configure the GStreamer Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``filesrc`` element and set some properties:\n",
    "* Set the ``location`` property to the path of the video file.\n",
    "* Set the ``loop`` property to ``True`` to play the video in a continuous loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"/usr/share/movies/Big_Buck_Bunny_4K.webm.360p.vp9.webm\"\n",
    "loop = True\n",
    "\n",
    "src = Gst.ElementFactory.make(\"multifilesrc\")\n",
    "src.set_property(\"location\", file_name)\n",
    "src.set_property(\"loop\", loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder source pad is created dynamically when it detects the incoming stream. The ``pad-added`` signal is emitted and this ``pad_added`` callback function is executed. It links the source pad of the decoder to the sink pad of the ``videoconvert`` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_added(element, pad):\n",
    "    global cvt\n",
    "    \n",
    "    sink_pad = cvt.get_static_pad(\"sink\")\n",
    "    if not sink_pad.is_linked():\n",
    "        pad.link(sink_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``decodebin`` element. The ``decodebin`` instantiates the ``matroskademux`` and ``vp9dec`` elements to demux and decode the sample video file. Currently supported video codecs are theora, vp8 and vp9. Theora video files typically use an ogg container, whereas vp8 and vp9 video files typically use a matroska/webm container.\n",
    "\n",
    "Register the above ``pad_added`` callback function with the ``pad-added`` signal of the ``decodebin`` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decodebin = Gst.ElementFactory.make(\"decodebin\")\n",
    "decodebin.connect(\"pad-added\", pad_added);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``videoconvert`` and ``jpegenc`` elements.\n",
    "\n",
    "The ``videoconvert`` element converts the I420 input format to YUY2.\n",
    "\n",
    "The ``jpegenc`` element compresses the YUY2 frame to JPEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvt = Gst.ElementFactory.make(\"videoconvert\")\n",
    "jpegenc = Gst.ElementFactory.make(\"jpegenc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a callback function ``new_sample`` that retrieves the JPEG data from a GStreamer buffer object and passes it to the ``display`` function of the ``IPython.display`` module which displays the video frame inside the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_sample(sink):  \n",
    "    sample = sink.pull_sample()\n",
    "    buffer = sample.get_buffer()\n",
    "    ret, info = buffer.map(Gst.MapFlags.READ)\n",
    "    \n",
    "    display(Image(data=info.data))\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    buffer.unmap(info)\n",
    "    \n",
    "    return Gst.FlowReturn.OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``appsink`` element and set some properties:\n",
    "* Set the ``drop`` property to ``True`` to drop old buffers when the buffer queue is full\n",
    "* Set the ``max-buffers`` property to 0 to queue an unlimited number of buffers\n",
    "* Set the ``emit-signals`` property to ``True`` to emit the ``new-sample`` signal\n",
    "\n",
    "Register the above ``new_sample`` callback function with the ``new-sample`` signal of the ``appsink`` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink = Gst.ElementFactory.make(\"appsink\")\n",
    "sink.set_property(\"drop\", True)\n",
    "sink.set_property(\"max_buffers\", 0)\n",
    "sink.set_property(\"emit-signals\", True)\n",
    "sink.connect(\"new-sample\", new_sample);\n",
    "\n",
    "# Uncomment the below code to read back the newly set property values\n",
    "#print(\"appsink properties: \")\n",
    "#print(\"drop: \" + str(sink.get_property(\"drop\")))\n",
    "#print(\"max_buffers: \" + str(sink.get_property(\"max_buffers\")))\n",
    "#print(\"emit-signals: \" + str(sink.get_property(\"emit-signals\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create and Run the GStreamer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline, add all elements, and link them together.\n",
    "\n",
    "**Note:** The ``decodebin`` element is not linked to the ``videoconvert`` element at this point. The link is created dynamically in the ``pad_added`` callback function once the ``decodebin`` pad has been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Gst.Pipeline.new(nb)\n",
    "\n",
    "pipeline.add(src)\n",
    "pipeline.add(decodebin)\n",
    "pipeline.add(cvt)\n",
    "pipeline.add(jpegenc)\n",
    "pipeline.add(sink)\n",
    "\n",
    "src.link(decodebin)\n",
    "cvt.link(jpegenc)\n",
    "jpegenc.link(sink);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``bus_call`` function listens on the bus for ``EOS`` and ``ERROR`` events. If any of these events occur, stop the pipeline (set to ``NULL`` state) and quit the main loop.\n",
    "\n",
    "In case of an ``ERROR`` event, parse and print the error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bus_call(bus, message, loop):\n",
    "    t = message.type\n",
    "    if t == Gst.MessageType.EOS:\n",
    "        sys.stdout.write(\"End-of-stream\\n\")\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    elif t == Gst.MessageType.ERROR:\n",
    "        err, debug = message.parse_error()\n",
    "        sys.stderr.write(\"Error: %s: %s\\n\" % (err, debug))\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline (set to ``PLAYING`` state), create the main loop and listen to messages on the bus. Register the ``bus_call`` callback function with the ``message`` signal of the bus. Start the main loop.\n",
    "\n",
    "The video frames will be displayed below the following code cell. \n",
    "\n",
    "To stop the pipeline, click the square shaped icon labelled 'Interrupt the kernel' in the top menu bar. Create a dot graph of the pipeline topology before stopping the pipeline. Quit the main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_state(Gst.State.PLAYING);\n",
    "\n",
    "loop = GLib.MainLoop()\n",
    "bus = pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\", bus_call, loop)\n",
    "\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    Gst.debug_bin_to_dot_file(pipeline, Gst.DebugGraphDetails.ALL, nb)\n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. View the GStreamer Pipeline Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register dot plugins for png export to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dot file to png and display the pipeline graph. The image will be displayed below the following code cell. Double click on the generate image file to zoom in.\n",
    "\n",
    "**Note:** This step may take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotfile = dotdir + \"/\" + nb + \".dot\"\n",
    "graph = pydot.graph_from_dot_file(dotfile, 'utf-8')\n",
    "display(Image(graph[0].create(None, 'png', 'utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you learned how to:\n",
    "1. Create a GStreamer pipeline that demonstrates how to decode a video file and play it back inside the jupyter notebook\n",
    "2. Export the pipeline topology as a dot file image and display it in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Copyright© 2019 Xilinx</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
