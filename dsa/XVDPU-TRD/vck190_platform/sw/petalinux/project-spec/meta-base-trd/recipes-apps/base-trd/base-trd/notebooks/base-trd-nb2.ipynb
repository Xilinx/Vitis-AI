{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to capture video from a V4L2 device and display it inside this jupyter notebook using the GStreamer multimedia framework.\n",
    "\n",
    "Four types of V4L2 devices are supported in this notebook:\n",
    "* Virtual Video Test driver (vivid)\n",
    "* USB Video Class (UVC) driver (usbcam)\n",
    "* MIPI CSI-2 capture pipeline using the Leopard IMX274 FMC daughter card (mipi)\n",
    "* HDMI Rx capture pipeline (hdmi)\n",
    "\n",
    "Vivid (https://www.kernel.org/doc/html/latest/media/v4l-drivers/vivid.html) is configured to emulate a USB webcam in software and hence does not require any additional hardware to run this notebook. By default, the notebook is configured to use vivid.\n",
    "\n",
    "The UVC driver (https://www.kernel.org/doc/html/latest/media/v4l-drivers/uvcvideo.html) is commonly used to capture video from a USB webcam.\n",
    "\n",
    "The Leopard IMX274 FMC daughter card (https://leopardimaging.com/product/csi-2-mipi-modules-i-pex/li-imx274mipi-fmc/) can be used to capture video through a MIPI CSI-2 interface. The MIPI CSI-2 capture pipeline is implemented inside the PL and includes a basic ISP.\n",
    "\n",
    "The HDMI Rx capture pipeline is implemented inside the PL.\n",
    "\n",
    "The video pipeline is composed of the following GStreamer elements:\n",
    "* The ``mediasrcbin`` element is used to capture video from a V4L2 device. It is a bin element on top of the standard ``v4l2src`` element which performs additional media pipeline initialization (if needed).\n",
    "* The ``jpegenc`` element is used to compress the raw video format to JPEG.\n",
    "* The ``appsink`` element is used to make the JPEG frames available to the jupyter notebook where they are displayed.\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Create a GStreamer video pipeline that captures video from a V4L2 device and displays the video inside this notebook.\n",
    "2. Create a GStreamer pipeline graph and view it inside this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all python modules required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, clear_output\n",
    "import glob\n",
    "import subprocess\n",
    "import pydot\n",
    "import sys\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "gi.require_version(\"GstApp\", \"1.0\")\n",
    "from gi.repository import GObject, GLib, Gst, GstApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Base TRD notebook 2 (nb2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = \"nb2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for saving the pipeline graph as dot file. Set the GStreamer debug dot directory environment variable to point to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotdir = \"/home/root/gst-dot/\" + nb\n",
    "!mkdir -p $dotdir\n",
    "%env GST_DEBUG_DUMP_DOT_DIR = $dotdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the GStreamer library. Enable debug by setting the debug string, set default to level 1 for all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gst.init(None)\n",
    "Gst.debug_set_threshold_from_string('*:1', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create and Configure the GStreamer Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``get_media_by_device`` function returns the matching media node for a given video capture source. The following sources are supported in this notebook:\n",
    "* ``vivid`` : virtual video device (default)\n",
    "* ``usb`` : requires USB webcam\n",
    "* ``mipi`` : platform1 only, requires FMC card\n",
    "* ``hdmi`` : platform3 only, requires HDMI input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_media_dev_by_name(src):\n",
    "    sources = {\n",
    "        'vivid' : 'vivid',\n",
    "        \"usb\" : 'uvcvideo',\n",
    "        'mipi' : 'vcap_csi',\n",
    "        'hdmi' : 'vcap_hdmi'\n",
    "    }\n",
    "    devices = glob.glob('/dev/media*')\n",
    "    for dev in devices:\n",
    "        proc = subprocess.run(['media-ctl', '-d', dev, '-p'], capture_output=True, encoding='utf8')\n",
    "        for line in proc.stdout.splitlines():\n",
    "            if sources[src] in line:\n",
    "                return dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the ``source`` based on available media devices for this platform. The default source is set to ``vivid``. Update the value next to the comment to select USB webcam MIPI single-sensor, or HDMI Rx if connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"vivid\" # Change source to vivid, usb, mipi , hdmi\n",
    "\n",
    "media_device = get_media_dev_by_name(source) \n",
    "if media_device is None:\n",
    "    raise Exception('Unable to find video source ' + source + '. Make sure the device is plugged in, powered, and the correct platform is used.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source pads of the ``mediasrcbin`` element are created dynamically when it detects the incoming stream. The ``pad-added`` signal is emitted and this ``pad_added`` callback function is executed. It links the source pads of the mediasrcbin elements to the sink pads of the ``caps`` elements.\n",
    "\n",
    "Set the ``io-mode`` to mmap on the pad which propagates to the ``v4l2src`` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_added(element, pad):\n",
    "    sink_pad = caps.get_static_pad(\"sink\")\n",
    "    if not sink_pad.is_linked():\n",
    "        pad.link(sink_pad)\n",
    "        pad.set_property(\"io-mode\", \"mmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``mediasrcbin`` element which is a bin element that uses the standard ``v4l2src`` element inside. Set the following some properties:\n",
    "* Set the ``media-device`` property to the desired media device node\n",
    "* Register the above ``pad_added`` callback function with the ``pad-added`` signal of the ``mediasrcbin`` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = Gst.ElementFactory.make(\"mediasrcbin\")\n",
    "src.set_property(\"media-device\", media_device)\n",
    "src.connect(\"pad_added\", pad_added);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a caps filter element to set the desired resolution (width and height) and format. The caps filter is configured to parse the mentioned properties from a string.\n",
    "\n",
    "The default resolution is set to 1280x720 and the format to YUY2 as those are commonly supported by USB webcams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1280\n",
    "height = 720\n",
    "fmt = \"YUY2\"\n",
    "\n",
    "cap_string = \"video/x-raw, width=\" + str(width) + \", height=\" + str(height) + \", format=\" + fmt\n",
    "if source == \"mipi\" or source == \"hdmi\":\n",
    "    fps = \"60/1\"\n",
    "    cap_string = cap_string + \", framerate=\" + fps\n",
    "\n",
    "caps = Gst.ElementFactory.make(\"capsfilter\")\n",
    "cap = Gst.Caps.from_string(cap_string)\n",
    "caps.set_property(\"caps\", cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``jpegenc`` element to compress the YUY2 video frame to JPEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpegenc = Gst.ElementFactory.make(\"jpegenc\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a callback function ``new_sample`` that retrieves the JPEG data from a GStreamer buffer object and passes it to the ``display`` function of the ``IPython.display`` module which displays the video frame inside the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_sample(sink):   \n",
    "    sample = sink.pull_sample()\n",
    "    buffer = sample.get_buffer()\n",
    "    ret, info = buffer.map(Gst.MapFlags.READ)\n",
    "    \n",
    "    display(Image(data=info.data))\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    buffer.unmap(info)\n",
    "    \n",
    "    return Gst.FlowReturn.OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``appsink`` element and set some properties:\n",
    "* Set the ``drop`` property to ``True`` to drop old buffers when the buffer queue is full\n",
    "* Set the ``max-buffers`` property to 0 to queue an unlimited number of buffers\n",
    "* Set the ``emit-signals`` property to ``True`` to emit the ``new-sample`` signal\n",
    "\n",
    "Register the above ``new_sample`` callback function with the ``new-sample`` signal of the ``appsink`` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink = Gst.ElementFactory.make(\"appsink\")\n",
    "sink.set_property(\"drop\", True)\n",
    "sink.set_property(\"max_buffers\", 0)\n",
    "sink.set_property(\"emit-signals\", True)\n",
    "sink.connect(\"new-sample\", new_sample);\n",
    "\n",
    "# Uncomment the below code to read back the newly set property values\n",
    "#print(\"appsink properties: \")\n",
    "#print(\"drop: \" + str(sink.get_property(\"drop\")))\n",
    "#print(\"max_buffers: \" + str(sink.get_property(\"max_buffers\")))\n",
    "#print(\"emit-signals: \" + str(sink.get_property(\"emit-signals\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create and Run the GStreamer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline, add all elements, and link them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Gst.Pipeline.new(nb)\n",
    "\n",
    "pipeline.add(src)\n",
    "pipeline.add(caps)\n",
    "pipeline.add(jpegenc)\n",
    "pipeline.add(sink)\n",
    "\n",
    "caps.link(jpegenc)\n",
    "jpegenc.link(sink);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``bus_call`` function listens on the bus for ``EOS`` and ``ERROR`` events. If any of these events occur, stop the pipeline (set to ``NULL`` state) and quit the main loop.\n",
    "\n",
    "In case of an ``ERROR`` event, parse and print the error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bus_call(bus, message, loop):\n",
    "    t = message.type\n",
    "    if t == Gst.MessageType.EOS:\n",
    "        sys.stdout.write(\"End-of-stream\\n\")\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    elif t == Gst.MessageType.ERROR:\n",
    "        err, debug = message.parse_error()\n",
    "        sys.stderr.write(\"Error: %s: %s\\n\" % (err, debug))\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline (set to ``PLAYING`` state), create the main loop and listen to messages on the bus. Register the ``bus_call`` callback function with the ``message`` signal of the bus. Start the main loop.\n",
    "\n",
    "The video frames will be displayed below the following code cell. \n",
    "\n",
    "To stop the pipeline, click the square shaped icon labelled 'Interrupt the kernel' in the top menu bar. Create a dot graph of the pipeline topology before stopping the pipeline. Quit the main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_state(Gst.State.PLAYING);\n",
    "\n",
    "loop = GLib.MainLoop()\n",
    "bus = pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\", bus_call, loop)\n",
    "\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    Gst.debug_bin_to_dot_file(pipeline, Gst.DebugGraphDetails.ALL, nb)\n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. View the GStreamer Pipeline Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register dot plugins for png export to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dot file to png and display the pipeline graph. The image will be displayed below the following code cell. Double click on the generate image file to zoom in.\n",
    "\n",
    "**Note:** This step may take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotfile = dotdir + \"/\" + nb + \".dot\"\n",
    "graph = pydot.graph_from_dot_file(dotfile, 'utf-8')\n",
    "display(Image(graph[0].create(None, 'png', 'utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you learned how to:\n",
    "1. Create a GStreamer pipeline that demonstrates how to capture video from a V4L2 device and play it back inside the jupyter notebook\n",
    "2. Export the pipeline topology as a dot file image and display it in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Copyright© 2019 Xilinx</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
