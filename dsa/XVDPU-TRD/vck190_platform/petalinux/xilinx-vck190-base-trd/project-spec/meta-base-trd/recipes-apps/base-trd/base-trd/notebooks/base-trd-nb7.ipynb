{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to split four video pipelines from a single source. Each branch runs through a 2d filter. This notebook uses 2d filter kernels available in PL HW. The kernels is time-multiplexed across four elements. The display device contains a video mixer which allows targeting different video planes for the four branches with programmable x/y-offsets as well as width and height. In addition, the memory bandwidth is measured and plotted in a parallel notebook.\n",
    "\n",
    "Five types of V4L2 devices are supported in this notebook:\n",
    "* Virtual Video Test driver (vivid)\n",
    "* USB Video Class (UVC) driver (usb)\n",
    "* MIPI CSI-2 capture pipeline using the Leopard IMX274 FMC daughter card (mipi)\n",
    "* MIPI CSI-2 capture pipeline using the Avnet Multi-Camera FMC Module (mipi_quad)\n",
    "* HDMI Rx HDR10 capture pipeline (hdmi)\n",
    "\n",
    "The video pipeline is composed of the following GStreamer elements:\n",
    "* The ``mediasrcbin`` element is used to capture video from a V4L2 device\n",
    "* The ``tee`` element is used to fork the input stream into multiple output streams, in this case 4 ouput streams\n",
    "* The ``ivas_xfilter`` vvas infrastructure plugin used to implement a 2D convolution filter. A total of 4 instances is used using the PL kernel. \n",
    "* The ``perf`` element is used to measure and print the frame rate in one of the forked paths.\n",
    "* The ``kmssink`` element is used to display video on a monitor using the DRM/KMS kernel subsystem. Four planes are used to display the four streams.\n",
    "\n",
    "The default input video resolution is set to 1280x720, hence the monitor needs to support a minimum resolution of 2560x1440 (or higher).\n",
    "\n",
    "The ``base-trd-apm`` notebook is executed in parallel to this notebook ro measure and plot the memory bandwidth of the live video pipeline.\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Create a GStreamer video pipeline with four branches using the ``parse_launch()`` API\n",
    "2. Run the ``base-trd-apm`` notebook to measure and plot the memory bandwidth while the video pipeline is running.\n",
    "3. Create a GStreamer pipeline graph and view it inside this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all python modules required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, clear_output\n",
    "import glob\n",
    "import subprocess\n",
    "import pydot\n",
    "import sys\n",
    "import os\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import GObject, GLib, Gst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Base TRD notebook 7 (nb7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = \"nb7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for saving the pipeline graph as dot file. Set the GStreamer debug dot directory environment variable to point to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotdir = \"/home/root/gst-dot/\" + nb\n",
    "!mkdir -p $dotdir\n",
    "%env GST_DEBUG_DUMP_DOT_DIR = $dotdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the correct Vitis Overlay is available in the platform for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xbutil_program_xclbin():\n",
    "    xclbin = os.path.join(\"/media/sd-mmcblk0p1\", \"binary_container_1.xclbin\")\n",
    "    if os.path.exists(xclbin):\n",
    "        subprocess.run(['xbutil', 'program', '-p', xclbin], check=True)\n",
    "\n",
    "def xbutil_query_cu(cu):\n",
    "    proc = subprocess.run(['xbutil', 'query'], capture_output=True, encoding='utf8')\n",
    "    for line in proc.stdout.splitlines():\n",
    "        if cu in line:\n",
    "            return\n",
    "    raise Exception(\"Unable to find compute unit \\'\" + cu + \"\\'. Make sure the correct Vitis overlay is used.\")\n",
    "\n",
    "xbutil_program_xclbin()\n",
    "xbutil_query_cu(\"filter2d_pl_accel_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the GStreamer library. Enable debug by setting the debug string, set default to level 1 for all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gst.init(None)\n",
    "Gst.debug_set_threshold_from_string('*:1', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run the APM Notebook to Plot the Memory Bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the ``base-trd-apm.ipynb`` notebook from the *File Browser* in a new tab. Execute the notebook by selecting *Run -> Run All Cells* from the Jupyter Lab menu bar. In section 4 of the APM notebook, a horizontal bar graph is shown that plots the currently consumed memory bandwidth split out by different AXI ports. For more information, read the APM notebook tutorial.\n",
    "\n",
    "Once you see the graph, right-click the graph and select *Create New View for Output*. This will create a new window/tab with just the graph. Now re-arrange the window by dragging it to the the right side of the screen so it shows side-by-side with the notebook window (see screenshot below).\n",
    "\n",
    "![APM Plot](images/apm-plot-nb6.jpg \"APM Plot\")\n",
    "\n",
    "Switch tabs back to the nb7 notebook and follow the steps below. Once the video pipeline is running, you will notice the bar graph will be updated live with the measured memory bandwidth numbers in Gbps. The screenshot shows video capture from the MIPI pipeline.\n",
    "\n",
    "**Note:** You can skip this step if your APM output view was already created previsouly. It will update automatically after running the video pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create String Representation of GStreamer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``get_media_by_device`` function returns the matching media node for a given video capture source. The following sources are supported in this notebook:\n",
    "* ``vivid`` : virtual video device (default)\n",
    "* ``usb`` : requires USB webcam\n",
    "* ``mipi`` : platform1 only, requires FMC card\n",
    "* ``mipi_quad`` : platform2 only, requires FMC card\n",
    "* ``hdmi`` : platform3 only, requires HDMI input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_media_dev_by_name(src):\n",
    "    sources = {\n",
    "        'vivid' : 'vivid',\n",
    "        \"usb\" : 'uvcvideo',\n",
    "        'mipi' : 'vcap_csi',\n",
    "        'mipi_quad' : 'vcap_gmsl',\n",
    "        'hdmi' : 'vcap_hdmi'\n",
    "    }\n",
    "    devices = glob.glob('/dev/media*')\n",
    "    for dev in devices:\n",
    "        proc = subprocess.run(['media-ctl', '-d', dev, '-p'], capture_output=True, encoding='utf8')\n",
    "        for line in proc.stdout.splitlines():\n",
    "            if sources[src] in line:\n",
    "                return dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the ``mediasrcbin`` element and its properties as string representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"vivid\" # Change source to vivid, usb, mipi, mipi_quad, or hdmi\n",
    "\n",
    "media_device = get_media_dev_by_name(source) \n",
    "if media_device is None:\n",
    "    raise Exception('Unable to find video source ' + source + '. Make sure the device is plugged in, powered, and the correct platform is used.')\n",
    "\n",
    "io_mode = \"mmap\"\n",
    "if source == \"mipi\" or source == \"mipi_quad\" or source== \"hdmi\":\n",
    "    io_mode = \"dmabuf\"\n",
    "\n",
    "src = \"mediasrcbin media-device=\" + media_device + \" name=src\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the ``caps`` filter element as string representation. Set the framerate if MIPI or MIPI quad is selected as source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1280\n",
    "height = 720\n",
    "fmt = \"YUY2\"\n",
    "\n",
    "caps = \"video/x-raw, width=\" + str(width) + \", height=\" + str(height) + \", format=\" + fmt \n",
    "\n",
    "if source == \"mipi\" or source== \"hdmi\":\n",
    "    fps = \"60/1\"\n",
    "    caps = caps + \", framerate=\" + fps\n",
    "elif source == \"mipi_quad\":\n",
    "    fps = \"30/1\"\n",
    "    caps = caps + \", framerate=\" + fps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the filter2d elements which can be time-multiplexed across multiple video pipelines. In this case, four instances of the filter2d element are used:\n",
    "1. Four PL filter2d elements with different filter presets using a single HW kernel. Presets are being dynamically configured. the first preset produces an edge effect (top left), the second is an emboss effect (top right), the third preset produces a sharpen effect (bottom left), the last preset is identity, which takes the default config values from json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_pl1 = 'ivas_xfilter kernels-config=/usr/share/ivas/base-trd/kernel_xfilter2d_pl.json dynamic-config={\"filter_preset\":\"edge\"}'\n",
    "filter_pl2 = 'ivas_xfilter kernels-config=/usr/share/ivas/base-trd/kernel_xfilter2d_pl.json dynamic-config={\"filter_preset\":\"emboss\"}'\n",
    "filter_pl3 = 'ivas_xfilter kernels-config=/usr/share/ivas/base-trd/kernel_xfilter2d_pl.json dynamic-config={\"filter_preset\":\"sharpen\"}'\n",
    "filter_pl4 = 'ivas_xfilter kernels-config=/usr/share/ivas/base-trd/kernel_xfilter2d_pl.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the ``kmssink`` element and its properties as string representation. Four planes with different x/y-offsets are used to display the four video streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plane 1\n",
    "plane_id_1 = 38\n",
    "xoff_1 = 0\n",
    "yoff_1 = 0\n",
    "render_rectangle_1 = \"<\" + str(xoff_1) + \",\" + str(yoff_1) + \",\" + str(width) + \",\" + str(height) + \">\"\n",
    "sink_1 = \"kmssink plane-id=\" + str(plane_id_1) + \" render-rectangle=\" + render_rectangle_1  + \" sync=false\"\n",
    "# plane 2\n",
    "plane_id_2 = 39\n",
    "xoff_2 = width\n",
    "yoff_2 = 0\n",
    "render_rectangle_2 = \"<\" + str(xoff_2) + \",\" + str(yoff_2) + \",\" + str(width) + \",\" + str(height) + \">\"\n",
    "sink_2 = \"kmssink plane-id=\" + str(plane_id_2) + \" render-rectangle=\" + render_rectangle_2 + \" sync=false\"\n",
    "# plane 3\n",
    "plane_id_3 = 40\n",
    "xoff_3 = 0\n",
    "yoff_3 = height\n",
    "render_rectangle_3 = \"<\" + str(xoff_3) + \",\" + str(yoff_3) + \",\" + str(width) + \",\" + str(height) + \">\"\n",
    "sink_3 = \"kmssink plane-id=\" + str(plane_id_3) + \" render-rectangle=\" + render_rectangle_3 + \" sync=false\"\n",
    "# plane 4\n",
    "plane_id_4 = 41\n",
    "xoff_4 = width\n",
    "yoff_4 = height\n",
    "render_rectangle_4 = \"<\" + str(xoff_4) + \",\" + str(yoff_4) + \",\" + str(width) + \",\" + str(height) + \">\"\n",
    "sink_4 = \"kmssink plane-id=\" + str(plane_id_4) + \" render-rectangle=\" + render_rectangle_4 + \" sync=false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a string representation of the pipeline by concatenating the individual element strings.\n",
    "\n",
    "If MIPI quad is selected, ``mediasrcbin`` is instantiated with four source pads, one for each sensor. the source pads are referenced by the name of the ``mediasrcbin`` element (``src``) followed by a dot (``src.``). For any other source, a ``tee`` element is used to fork the source. Each branch is referenced by the name of the ``tee`` element (``src``) followed by a dot (``src.``). The ``queue`` element is used to create a new thread for each branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source == \"mipi_quad\":\n",
    "    t = \" src. ! \" + caps\n",
    "else:\n",
    "    src = src + \" v4l2src0::io-mode=\" + io_mode + \" ! \" + caps + \" ! tee name=t\"\n",
    "    t = \" t. \"\n",
    "\n",
    "pipe = src + \\\n",
    "    t + \" ! queue ! \" + filter_pl1  + \" ! queue ! perf ! \" + sink_1 + \" \" + \\\n",
    "    t + \" ! queue ! \" + filter_pl2  + \" ! queue ! \" + sink_2 + \" \" + \\\n",
    "    t + \" ! queue ! \" + filter_pl3 + \" ! queue ! \" + sink_3 + \" \" + \\\n",
    "    t + \" ! queue ! \" + filter_pl4 + \" ! queue ! \" + sink_4\n",
    "\n",
    "print (pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create and Run the GStreamer Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the string representations of the first and second pipeline as a single pipeline graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Gst.parse_launch(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``bus_call`` function listens on the bus for ``EOS``, ``INFO`` and ``ERROR`` events. In case of ``EOS`` or ``ERROR``, stop the pipeline (set to ``NULL`` state) and quit the main loop. \n",
    "\n",
    "For ``INFO`` and ``ERROR`` events, parse and print the info/error message. The ``perf`` element generates ``INFO`` events with the measured frame rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bus_call(bus, message, loop):\n",
    "    t = message.type\n",
    "    if t == Gst.MessageType.EOS:\n",
    "        sys.stdout.write(\"End-of-stream\\n\")\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    elif t == Gst.MessageType.INFO:\n",
    "        err, info = message.parse_info()\n",
    "        sys.stderr.write(\"Info: %s\\n\" % info)\n",
    "        clear_output(wait=True)\n",
    "    elif t == Gst.MessageType.ERROR:\n",
    "        err, debug = message.parse_error()\n",
    "        sys.stderr.write(\"Error: %s: %s\\n\" % (err, debug))\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline (set to ``PLAYING`` state), create the main loop and listen to messages on the bus. Register the ``bus_call`` callback function with the ``message`` signal of the bus. Start the main loop.\n",
    "\n",
    "The video will be displayed on the monitor. The frame rate will be printed and updated below the code cell.\n",
    "\n",
    "To stop the pipeline, click the square shaped icon labelled 'Interrupt the kernel' in the top menu bar. Create a dot graph of the pipeline topology before stopping the pipeline. Quit the main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_state(Gst.State.PLAYING);\n",
    "\n",
    "loop = GLib.MainLoop()\n",
    "bus = pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\", bus_call, loop)\n",
    "\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    Gst.debug_bin_to_dot_file(pipeline, Gst.DebugGraphDetails.ALL, nb)\n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. View the Pipeline dot Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dot file to png and display the pipeline graph. The image will be displayed below the following code cell. Double click on the generate image file to zoom in.\n",
    "\n",
    "**Note:** This step may take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotfile = dotdir + \"/\" + nb + \".dot\"\n",
    "graph = pydot.graph_from_dot_file(dotfile, 'utf-8')\n",
    "display(Image(graph[0].create(None, 'png', 'utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you learned how to:\n",
    "1. Create a GStreamer pipeline with four branches from a string representation using the ``parse_launch()`` API\n",
    "2. Plot the live memory bandwidth by running the APM notebook in parallel\n",
    "3. Export the pipeline topology as a dot file image and display it in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>CopyrightÂ© 2019 Xilinx</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
