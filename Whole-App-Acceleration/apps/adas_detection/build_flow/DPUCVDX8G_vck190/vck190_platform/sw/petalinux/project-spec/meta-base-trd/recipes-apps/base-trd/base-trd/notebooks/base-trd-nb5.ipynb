{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to capture video from a quad sensor MIPI CSI-2 interface and display the output on a monitor using a DRM/KMS device. This notebook uses the GStreamer multimedia framework. The display device contains a video mixer which allows targeting 4 input video streams onto different video planes with programmable x/y-offsets as well as width and height. \n",
    "\n",
    "V4L2 devices that are supported in this notebook:\n",
    "* MIPI CSI-2 capture pipeline using the Avnet Multi-Camera FMC Module (mipi_quad)\n",
    "\n",
    "The Avnet Multi-Camera FMC Module (https://www.avnet.com/wps/portal/silica/products/new-products/npi/2018/avnet-multi-camera-fmc-module/) can be used to capture 4 video streams through a MIPI CSI-2 interface. The MIPI CSI-2 capture pipelines are implemented inside the PL and includes a basic ISP.\n",
    "\n",
    "The video pipeline is composed of the following GStreamer elements:\n",
    "* The ``mediasrcbin`` element is used to capture video from a V4L2 device. It is a bin element on top of the standard ``v4l2src`` element which performs additional media pipeline initialization (if needed).\n",
    "* The ``perf`` element is used to measure and print the frame rate\n",
    "* The ``kmssink`` element is used to display video on a monitor using the DRM/KMS kernel subsystem\n",
    "\n",
    "In this notebook, you will:\n",
    "1. Create a GStreamer video pipeline that captures video from Avnet Multi-Camera FMC Module and displays the video on a monitor using a DRM/KMS device.\n",
    "2. Create a GStreamer pipeline graph and view it inside this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all python modules required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, clear_output\n",
    "import glob\n",
    "import subprocess\n",
    "import pydot\n",
    "import sys\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import GObject, GLib, Gst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Base TRD notebook 5 (nb5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = \"nb5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for saving the pipeline graph as dot file. Set the GStreamer debug dot directory environment variable to point to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotdir = \"/home/root/gst-dot/\" + nb\n",
    "!mkdir -p $dotdir\n",
    "%env GST_DEBUG_DUMP_DOT_DIR = $dotdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the GStreamer library. Enable debug by setting the debug string, set default to level 1 for all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gst.init(None)\n",
    "Gst.debug_set_threshold_from_string('*:1', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create and Configure the GStreamer Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``get_media_by_device`` function returns the matching media node for a given video capture source. The following sources are supported in this notebook:\n",
    "* ``mipi_quad`` : platform2 only, requires FMC card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_media_dev_by_name(src):\n",
    "    sources = {\n",
    "        'mipi_quad' : 'vcap_gmsl'\n",
    "    }\n",
    "    devices = glob.glob('/dev/media*')\n",
    "    for dev in devices:\n",
    "        proc = subprocess.run(['media-ctl', '-d', dev, '-p'], capture_output=True, encoding='utf8')\n",
    "        for line in proc.stdout.splitlines():\n",
    "            if sources[src] in line:\n",
    "                return dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the quad-sensor MIPI device as ``source`` based on available media devices for this platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"mipi_quad\"\n",
    "media_device = get_media_dev_by_name(source) \n",
    "if media_device is None:\n",
    "    raise Exception('Unable to find video source ' + source + '. Make sure the device is plugged in, powered, and the correct platform is used.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source pads of the ``mediasrcbin`` element are created dynamically when it detects the incoming stream. The ``pad-added`` signal is emitted and this ``pad_added`` callback function is executed. It links the source pads of the mediasrcbin elements to the sink pads of the ``caps`` elements.\n",
    "\n",
    "Set the ``io-mode`` on all the pads to ``dmabuf``. This will propagate to all the ``v4l2src`` elements inside the bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "def pad_added(element, pad):\n",
    "    caps_array = [caps0, caps1, caps2, caps3]\n",
    "    global index \n",
    "    \n",
    "    sink_pad = caps_array[index].get_static_pad(\"sink\")\n",
    "    if not sink_pad.is_linked():\n",
    "        pad.link(sink_pad)\n",
    "        pad.set_property(\"io-mode\", \"dmabuf\")\n",
    "        \n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``mediasrcbin`` element which is a bin element that uses the standard ``v4l2src`` element inside. Set the following some properties:\n",
    "* Set the ``media-device`` property to the desired media device node\n",
    "* Register the above ``pad_added`` callback function with the ``pad-added`` signal of the ``mediasrcbin`` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src0 = Gst.ElementFactory.make(\"mediasrcbin\")\n",
    "src0.set_property(\"media-device\", media_device)\n",
    "src0.connect(\"pad_added\", pad_added);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create four caps filter element to set the desired resolution (width and height) and format. The caps filter is configured to parse the mentioned properties from a string.\n",
    "The default resolution is set to 960x480 and the format to YUY2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 960\n",
    "height = 540\n",
    "fmt = \"YUY2\"\n",
    "framerate = \"30/1\"\n",
    "\n",
    "cap = Gst.Caps.from_string(\"video/x-raw, width=\" + str(width) + \", height=\" + str(height) + \", format=\" + fmt + \", framerate=\" + framerate)\n",
    "\n",
    "caps0 = Gst.ElementFactory.make(\"capsfilter\")\n",
    "caps0.set_property(\"caps\", cap)\n",
    "\n",
    "caps1 = Gst.ElementFactory.make(\"capsfilter\")\n",
    "caps1.set_property(\"caps\", cap)\n",
    "\n",
    "caps2 = Gst.ElementFactory.make(\"capsfilter\")\n",
    "caps2.set_property(\"caps\", cap)\n",
    "\n",
    "caps3 = Gst.ElementFactory.make(\"capsfilter\")\n",
    "caps3.set_property(\"caps\", cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``perf`` element which is used to measure and print the frame rate while the video pipeline is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = Gst.ElementFactory.make(\"perf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The display driver creates a DRM device node with the module name ``xlnx``.\n",
    "\n",
    "List information about the DRM device by passing the module name to the ``modeprint`` utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!modeprint xlnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``kmssink`` element and set some properties:\n",
    "* Set the ``plane-id`` property to the ID value of the target plane. The default value 30 is set to the first RGB plane.\n",
    "* Set the ``render-rectangle`` property to a quadruple consisting of x-offset, y-offset, width, and height. The render-rectangle allows moving a plane position on the display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_id0 = 38\n",
    "plane_id1 = 39\n",
    "plane_id2 = 40\n",
    "plane_id3 = 41\n",
    "\n",
    "render_rectangle0 = Gst.ValueArray((0, 0, width, height))\n",
    "render_rectangle1 = Gst.ValueArray((width, 0, width, height))\n",
    "render_rectangle2 = Gst.ValueArray((0, height, width, height))\n",
    "render_rectangle3 = Gst.ValueArray((width, height, width, height))\n",
    "\n",
    "sink0 = Gst.ElementFactory.make(\"kmssink\")\n",
    "sink0.set_property(\"plane-id\", plane_id0)\n",
    "sink0.set_property(\"render-rectangle\", render_rectangle0)\n",
    "\n",
    "sink1 = Gst.ElementFactory.make(\"kmssink\")\n",
    "sink1.set_property(\"plane-id\", plane_id1)\n",
    "sink1.set_property(\"render-rectangle\", render_rectangle1)\n",
    "\n",
    "sink2 = Gst.ElementFactory.make(\"kmssink\")\n",
    "sink2.set_property(\"plane-id\", plane_id2)\n",
    "sink2.set_property(\"render-rectangle\", render_rectangle2)\n",
    "\n",
    "sink3 = Gst.ElementFactory.make(\"kmssink\")\n",
    "sink3.set_property(\"plane-id\", plane_id3)\n",
    "sink3.set_property(\"render-rectangle\", render_rectangle3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create and Run the GStreamer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline, add all elements, and link them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Gst.Pipeline.new(nb)\n",
    "\n",
    "pipeline.add(src0)\n",
    "pipeline.add(caps0)\n",
    "pipeline.add(sink0)\n",
    "pipeline.add(caps1)\n",
    "pipeline.add(sink1)\n",
    "pipeline.add(caps2)\n",
    "pipeline.add(sink2)\n",
    "pipeline.add(caps3)\n",
    "pipeline.add(perf)\n",
    "pipeline.add(sink3)\n",
    "\n",
    "caps0.link(sink0)\n",
    "caps1.link(sink1)\n",
    "caps2.link(sink2)\n",
    "caps3.link(perf)\n",
    "perf.link(sink3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``bus_call`` function listens on the bus for ``EOS`` and ``ERROR`` events. If any of these events occur, stop the pipeline (set to ``NULL`` state) and quit the main loop.\n",
    "\n",
    "In case of an ``ERROR`` event, parse and print the error message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline (set to ``PLAYING`` state), create the main loop and listen to messages on the bus. Register the ``bus_call`` callback function with the ``message`` signal of the bus. Start the main loop.\n",
    "\n",
    "The video frames will be displayed on the HDMI monitor connected to the target. \n",
    "\n",
    "To stop the pipeline, click the square shaped icon labelled 'Interrupt the kernel' in the top menu bar. Create a dot graph of the pipeline topology before stopping the pipeline. Quit the main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bus_call(bus, message, loop):\n",
    "    t = message.type\n",
    "    if t == Gst.MessageType.EOS:\n",
    "        sys.stdout.write(\"End-of-stream\\n\")\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    elif t == Gst.MessageType.INFO:\n",
    "        err, info = message.parse_info()\n",
    "        sys.stderr.write(\"Info: %s\\n\" % info)\n",
    "        clear_output(wait=True)\n",
    "    elif t == Gst.MessageType.ERROR:\n",
    "        err, debug = message.parse_error()\n",
    "        sys.stderr.write(\"Error: %s: %s\\n\" % (err, debug))\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_state(Gst.State.PLAYING);\n",
    "loop = GLib.MainLoop()\n",
    "bus = pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\", bus_call, loop)\n",
    "\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    Gst.debug_bin_to_dot_file(pipeline, Gst.DebugGraphDetails.ALL, nb)\n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. View the GStreamer Pipeline Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register dot plugins for png export to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dot file to png and display the pipeline graph. The image will be displayed below the following code cell. Double click on the generate image file to zoom in.\n",
    "\n",
    "**Note:** This step may take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotfile = dotdir + \"/\" + nb + \".dot\"\n",
    "graph = pydot.graph_from_dot_file(dotfile, 'utf-8')\n",
    "display(Image(graph[0].create(None, 'png', 'utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you learned how to:\n",
    "1. Create a GStreamer pipeline that demonstrates how to capture video from Avnet Multi-Camera FMC Module and display the video on a monitor using a DRM/KMS device.\n",
    "2. Export the pipeline topology as a dot file image and display it in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>CopyrightÂ© 2019 Xilinx</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
