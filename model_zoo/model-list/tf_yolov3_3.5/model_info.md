# YOLOv3

### Contents
1. [Use Case and Application](#Use-Case-and-Application)
2. [Specification](#Specification)
3. [Paper and Architecture](#Paper-and-Architecture)
4. [Dataset Preparation](#Dataset-Preparation)
5. [Use Guide](#Use-Guide)
6. [License](#License)
7. [Note](#Note)


### Use Case and Application

   - Classic Object Detection
   - Trained on VOC dataset
   
   
### Specification

| Metric             | Value                                   |
| :----------------- | :-------------------------------------- |
| Framework          | TensorFlow2                             |
| Prune Ratio        | 0%                                      |
| FLOPs              | 65.63G                                  |
| Input Dims (H W C) | 416,416,3                               |
| FP32 Accuracy      | 0.7846 mAP                              |
| INT8 Accuracy      | 0.7729 mAP                              |
| Train Dataset      | voc07+12_trainval	                   |
| Test Dataset       | voc07_test                              |
| Supported Platform | GPU, VEK280, V70                        |
  

### Paper and Architecture 

1. Network Architecture: YOLOv3

2. Paper Link: https://arxiv.org/abs/1804.02767

   
### Dataset Preparation

1. Dataset description

The model is trained on VOC2007_trainval + VOC2012_trainval and tested on VOC2007_test.

2. Download and prepare the dataset

Our script `prepare_data.sh` downloads and prepares the dataset automatically. But if you have downloaded the VOC2007 test set before, you could place them in the `data` directory manually and choose to skip downloading the dataset when the script asking for a choice. Run the script: 
  ```shell
  bash code/test/dataset_tools/prepare_data.sh
  ```
Dataset diretory structure
  ```shell
  # VOCdevkit is unpacked from the downloaded data
  # voc2007_test is generated by our code for data preparation
  + data
    + VOCdevkit
      + VOC2007
        + ImageSets
        + JPEGImages
        + Annotations
    + voc2007_test
      + images
        + 000001.jpg
        + 000002.jpg
        + ...
      + test.txt
      + gt_detection.txt
  ```


### Use Guide

1. Evaluation
    Configure the model path and data path in [code/test/run_eval.sh](code/test/run_eval.sh)
    ```shell
    bash code/test/run_eval.sh
    ```
  
   
### License

Apache License 2.0

For details, please refer to **[Vitis-AI License](https://github.com/Xilinx/Vitis-AI/blob/master/LICENSE)**


### Note

1. Data preprocess
  ```
  data channel order: RGB(0~255)
  input = input / 255
  resize: keep aspect ratio of the raw image and resize it to make the length of the longer side equal to 416
  padding: pad along the short side with 0.5 to generate the input image with size = 416 x 416
  ``` 
2. Node information

  ```
  input node: 'input_1:0'
  output nodes: 'conv2d_59/BiasAdd:0', 'conv2d_67/BiasAdd:0', 'conv2d_75/BiasAdd:0'
  ```
  

### Quantize

1. Quantize tool installation

   Please refer to [vai_q_tensorflow](../../../src/vai_quantizer/vai_q_tensorflow1.x)
  
2. Quantize workspace

   You could use code/quantize/ folder.
