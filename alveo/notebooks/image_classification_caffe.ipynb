{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with Caffe\n",
    "\n",
    "This tutorial demonstrates the steps required to prepare and deploy a trained Caffe model for FPGA acceleration using Xilinx MLSuite:  \n",
    "1. **Quantize the model** - The quantizer will generate scaling parameters for quantizing floats INT8. This is required, because FPGAs will take advantage of Fixed Point Precision, to achieve more parallelization at lower power. \n",
    "2. **Compile the Model** - In this step, the network Graph (prototxt) and the Weights (caffemodel) are compiled, the compiler \n",
    "3. **Subgraph Cutting** - In this step, the original graph is cut, and a custom FPGA accelerated python layer is inserted to be used for Inference. \n",
    "4. **Classification** - In this step, the caffe model and the prototxt from the previous step are run on the FPGA to perform inference on an input image.\n",
    "  \n",
    "For command line versions see: examples/caffe/  \n",
    "  \n",
    "## Prerequisite Files\n",
    "1. **Model files** - This notebook requires that model files are located in  \n",
    "  `$VAI_ALVEO_ROOT/examples/caffe/models/`\n",
    "2. **Image files** - This notebook requires ilsvrc2012 image files are downloaded in  \n",
    "  `$HOME/CK-TOOLS/dataset-imagenet-ilsvrc2012-val-min/`\n",
    "  \n",
    "## Setup (Before Running Notebook)\n",
    "**Note:** User is responsible for the use of the downloaded content and compliance with any copyright licenses.\n",
    "\n",
    "```\n",
    "conda activate vitis-ai-caffe\n",
    "python -m ck pull repo:ck-env\n",
    "python -m ck install package:imagenet-2012-val-min\n",
    "python -m ck install package:imagenet-2012-aux\n",
    "head -n 500 $HOME/CK-TOOLS/dataset-imagenet-ilsvrc2012-aux/val.txt > $HOME/CK-TOOLS/dataset-imagenet-ilsvrc2012-val-min/val_map.txt\n",
    "cd $VAI_ALVEO_ROOT/examples/caffe\n",
    "python resize.py $HOME/CK-TOOLS/dataset-imagenet-ilsvrc2012-val-min 256 256\n",
    "python getModels.py\n",
    "source $VAI_ALVEO_ROOT/overlaybins/setup.sh\n",
    "python replace_mluser.py --modelsdir models\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "from IPython.display import Image as display\n",
    "from ipywidgets import interact\n",
    "\n",
    "import numpy as np\n",
    "from caffe import Classifier, io\n",
    "from caffe.proto import caffe_pb2\n",
    "from caffe.draw import draw_net_to_file\n",
    "from google.protobuf import text_format\n",
    "\n",
    "# Environment Variables (\"source overlaybins/setup.sh\")\n",
    "VAI_ALVEO_ROOT = os.getenv(\"VAI_ALVEO_ROOT\",os.getcwd()+\"/..\")\n",
    "XCLBIN = \"/opt/xilinx/overlaybins/xdnnv3\"\n",
    "\n",
    "print(\"Running w/ VAI_ALVEO_ROOT: %s\" % VAI_ALVEO_ROOT)\n",
    "print(\"Running w/ XCLBIN: %s\" % XCLBIN)\n",
    "\n",
    "# Bring in SubGraph Cutter\n",
    "from decent import CaffeFrontend as xfdnnQuantizer\n",
    "from vai.dpuv1.rt.scripts.framework.caffe.xfdnn_subgraph import CaffeCutter as xfdnnCutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete stale directories\n",
    "if os.path.exists(\"quantize_results\"):\n",
    "    shutil.rmtree(\"quantize_results\")\n",
    "if os.path.exists(\"work\"):\n",
    "    shutil.rmtree(\"work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Choose a model\n",
    "Choose a model using the drop down, or select custom, and enter your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(MODEL=[\"bvlc_googlenet\",\"inception_v2\",\"inception_v3\",\"inception_v4\",\\\n",
    "                    \"resnet50_v1\",\"resnet50_v2\",\"squeezenet\",\"vgg16\",\"custom\"])\n",
    "def selectModel(MODEL):\n",
    "    global prototxt\n",
    "    global caffemodel\n",
    "    global name\n",
    "    model_root = VAI_ALVEO_ROOT + \"/examples/caffe/models/\"\n",
    "    if MODEL == \"custom\":\n",
    "        prototxt = None\n",
    "        caffemodel = None\n",
    "        name = None\n",
    "    else:\n",
    "        prototxt = model_root + MODEL + \"/\" + MODEL + \"_train_val.prototxt\"\n",
    "        caffemodel = model_root + MODEL + \"/\" + MODEL + \".caffemodel\"\n",
    "        name = MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not prototxt:\n",
    "    @interact(PROTOTXT=\"Provide the path to your prototxt\")\n",
    "    def selectPrototxt(PROTOTXT):\n",
    "        global prototxt\n",
    "        prototxt = PROTOTXT\n",
    "    @interact(CAFFEMODEL=\"Provide the path to your caffemodel\")\n",
    "    def selectCaffemodel(CAFFEMODEL):\n",
    "        global caffemodel\n",
    "        caffemodel = CAFFEMODEL\n",
    "    @interact(MODEL=\"Provide a name to your model\")\n",
    "    def selectCaffemodel(MODEL):\n",
    "        global name\n",
    "        name = MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Currently running : %s\" % name)\n",
    "print(\"Running with prototxt:   %s\" % prototxt)\n",
    "print(\"Running with caffemodel: %s\" % caffemodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Run the Quantizer\n",
    "\n",
    "Here, we will quantize the model. The inputs are model prototxt, model weights, number of test iterations and calibration iterations. The output is quantized prototxt, weights, and quantize_info.txt and will be generated in the quantize_results/ directory.\n",
    "\n",
    "The Quantizer will generate a json file holding scaling parameters for quantizing floats to INT8\n",
    "This is required, because FPGAs will take advantage of Fixed Point Precision, to achieve accelerated inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantize(prototxt,caffemodel,calib_iter=1,output_dir=\"quantize_results\"):\n",
    "    os.environ[\"DECENT_DEBUG\"] = \"1\"\n",
    "    subprocess.call([\"vai_q_caffe\", \"quantize\",\n",
    "                 \"--model\", prototxt,\n",
    "                 \"--weights\", caffemodel,\n",
    "                 \"--calib_iter\", str(calib_iter)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quantize(prototxt,caffemodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the Compiler\n",
    "\n",
    "The compiler takes in the quantizer outputs from the previous step (prototxt, weights, quantize_info) and outputs a compiler.json and quantizer.json.\n",
    "\n",
    "* A Network Graph (prototxt) and a Weights Blob (caffemodel) are compiled\n",
    "* The network is optimized\n",
    "* FPGA Instructions are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"/opt/vitis_ai/compiler/arch/DPUCADX8G/ALVEO/arch.json\" # Informs compiler what underlying hardware is capable of\n",
    "\n",
    "def Compile(prototxt=\"quantize_results/deploy.prototxt\",\\\n",
    "            caffemodel=\"quantize_results/deploy.caffemodel\",\\\n",
    "            quantize_info=\"quantize_results/quantize_info.txt\"):\n",
    "    \n",
    "    subprocess.call([\"vai_c_caffe\",\n",
    "                    \"--prototxt\", prototxt,\n",
    "                    \"--caffemodel\", caffemodel,\n",
    "                    \"--net_name\", name,\n",
    "                    \"--output_dir\", \"work\",\n",
    "                    \"--arch\", arch,\n",
    "                    \"--options\", \"{\\\"quant_cfgfile\\\":\\\"%s\\\"}\" %(quantize_info)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the Subgraph Cutter\n",
    "\n",
    "The subgraph cutter creates a custom python layer to be accelerated on the FPGA. The inputs are compiler.json, quantizer.json and model weights from the compiler step, as well as the FPGA xclbin. This outputs a cut prototxt file with FPGA references, to be used for inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cut(prototxt):\n",
    "    \n",
    "    cutter = xfdnnCutter(\n",
    "        inproto=\"quantize_results/deploy.prototxt\",\n",
    "        trainproto=prototxt,\n",
    "        outproto=\"xfdnn_auto_cut_deploy.prototxt\",\n",
    "        outtrainproto=\"xfdnn_auto_cut_train_val.prototxt\",\n",
    "        cutAfter=\"data\",\n",
    "        xclbin=XCLBIN,\n",
    "        netcfg=\"work/compiler.json\",\n",
    "        quantizecfg=\"work/quantizer.json\",\n",
    "        weights=\"work/weights.h5\"\n",
    "    )\n",
    "    \n",
    "    cutter.cut()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cut(prototxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualize the new graph with the FPGA subgraph\n",
    "net = caffe_pb2.NetParameter()\n",
    "text_format.Merge(open(\"xfdnn_auto_cut_deploy.prototxt\").read(), net)\n",
    "draw_net_to_file(net,\"xfdnn_auto_cut_deploy.png\")\n",
    "display(\"xfdnn_auto_cut_deploy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Inference \n",
    "\n",
    "The inputs are the FPGA prototxt file, caffemodel weights, a test image, and the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classify(prototxt,caffemodel,image,labels):\n",
    "    classifier = Classifier(prototxt,caffemodel,\n",
    "        mean=np.array([104,117,123]),\n",
    "        raw_scale=255, channel_swap=[2,1,0])\n",
    "\n",
    "    predictions = classifier.predict([io.load_image(image)]).flatten()\n",
    "    labels = np.loadtxt(labels, str, delimiter='\\t')\n",
    "    top_k = predictions.argsort()[-1:-6:-1]\n",
    "    for l,p in zip(labels[top_k],predictions[top_k]):\n",
    "        print (l,\" : \",p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose image to run, display it for reference\n",
    "HOME = os.getenv(\"HOME\")\n",
    "image = HOME+\"/CK-TOOLS/dataset-imagenet-ilsvrc2012-val-min/ILSVRC2012_val_00000002.JPEG\"\n",
    "display(filename=image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classify(\"xfdnn_auto_cut_deploy.prototxt\",\"quantize_results/deploy.caffemodel\",image,HOME+\"/CK-TOOLS/dataset-imagenet-ilsvrc2012-aux/synset_words.txt\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This notebook demonstrates how to target Xilinx FPGAs for inference using Caffe.    \n",
    "When the time comes to take your application to production please look at examples in /workspace/alveo/examples/deployment_modes/  \n",
    "Highest performance is acheived by creating multiprocess pipelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}