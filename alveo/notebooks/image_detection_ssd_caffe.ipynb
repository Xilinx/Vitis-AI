{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Detection with Caffe\n",
    "\n",
    "This tutorial demonstrates the steps required to prepare and deploy a trained Caffe model for FPGA acceleration using Xilinx MLSuite:  \n",
    "1. **Quantize the model** - The quantizer will generate scaling parameters for quantizing floats INT8. This is required, because FPGAs will take advantage of Fixed Point Precision, to achieve more parallelization at lower power. \n",
    "2. **Compile the Model** - In this step, the network Graph (prototxt) and the Weights (caffemodel) are compiled, the compiler \n",
    "3. **Subgraph Cutting** - In this step, the original graph is cut, and a custom FPGA accelerated python layer is inserted to be used for Inference. \n",
    "4. **Detection** - In this step, the caffe model and the prototxt from the previous step are run on the FPGA to perform inference on an input image.\n",
    "  \n",
    "For command line versions see: examples/caffe/  \n",
    "  \n",
    "## Prerequisite Files\n",
    "1. **Model files** - This notebook requires that model files are located in  \n",
    "  `/workspace/alveo/examples/caffe/models`\n",
    "2. **Image files** - This notebook requires VOC image files are downloaded in  \n",
    "  `/workspace/alveo/examples/caffe/ssd-detect/VOCdevkit`\n",
    "  \n",
    "## Setup (Before Running Notebook)\n",
    "```\n",
    "cd /workspace/alveo/examples/caffe/ssd-detect \n",
    "# Download VOC2007 data.\n",
    "wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n",
    "# Extract the data.\n",
    "tar -xvf VOCtest_06-Nov-2007.tar\n",
    "#Generate ground truth file \n",
    "python generate_gt_file.py\n",
    "# VOC dataset contains 21 classes. But this model is trained with 19 classes (removed diningtable and train). \n",
    "If your model is having 21 classes, comment 40 line in generate_gt_file.py\n",
    "source $VAI_ALVEO_ROOT/overlaybins/setup.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# Bring in Quantizer, Compiler, SubGraph Cutter\n",
    "from decent import CaffeFrontend as xfdnnQuantizer\n",
    "from vai.dpuv1.rt.scripts.framework.caffe.xfdnn_subgraph import CaffeCutter as xfdnnCutter\n",
    "\n",
    "# Environment Variables (\"source overlaybins/setup.sh\")\n",
    "import os,sys,shutil,subprocess\n",
    "\n",
    "VAI_ALVEO_ROOT = os.getenv(\"VAI_ALVEO_ROOT\",\"../\")\n",
    "sys.path.append(VAI_ALVEO_ROOT + '/examples/caffe/ssd-detect')\n",
    "print(\"Running w/ VAI_ALVEO_ROOT: %s\" % VAI_ALVEO_ROOT)\n",
    "\n",
    "from IPython.display import Image as display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Choose a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"image_detection\"\n",
    "prototxt = VAI_ALVEO_ROOT + \"/examples/caffe/models/inception_v2_ssd/inception_v2_ssd_train.prototxt\"\n",
    "caffemodel = VAI_ALVEO_ROOT + \"/examples/caffe/models/inception_v2_ssd/inception_v2_ssd.caffemodel\"\n",
    "\n",
    "print(\"Currently running : %s\" % name)\n",
    "print(\"Running with prototxt:   %s\"%prototxt)\n",
    "print(\"Running with caffemodel: %s\"%caffemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up directories\n",
    "if os.path.exists(\"quantize_results\"):\n",
    "    shutil.rmtree(\"quantize_results\")\n",
    "if os.path.exists(\"work\"):\n",
    "    shutil.rmtree(\"work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Run the Quantizer\n",
    "\n",
    "Here, we will quantize the model. The inputs are model prototxt, model weights, number of test iterations and calibration iterations. The output is quantized prototxt, weights, and quantize_info.txt and will be generated in the quantize_results/ directory.\n",
    "\n",
    "The Quantizer will generate a json file holding scaling parameters for quantizing floats to INT8\n",
    "This is required, because FPGAs will take advantage of Fixed Point Precision, to achieve accelerated inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantize(prototxt,caffemodel,calib_iter=1,output_dir=\"quantize_results\"):\n",
    "    os.environ[\"DECENT_DEBUG\"] = \"1\"\n",
    "    subprocess.call([\"vai_q_caffe\", \"quantize\",\n",
    "                 \"--model\", prototxt,\n",
    "                 \"--weights\", caffemodel,\n",
    "                 \"--calib_iter\", str(calib_iter)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quantize(prototxt,caffemodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the Compiler\n",
    "\n",
    "The compiler takes in the quantizer outputs from the previous step (prototxt, weights, quantize_info) and outputs a compiler.json and quantizer.json.\n",
    "\n",
    "* A Network Graph (prototxt) and a Weights Blob (caffemodel) are compiled\n",
    "* The network is optimized\n",
    "* FPGA Instructions are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compile(prototxt=\"quantize_results/deploy.prototxt\",\\\n",
    "            caffemodel=\"quantize_results/deploy.caffemodel\",\\\n",
    "            quantize_info=\"quantize_results/quantize_info.txt\"):\n",
    "    \n",
    "    subprocess.call([\"vai_c_caffe\",\n",
    "                    \"--prototxt\", prototxt,\n",
    "                    \"--caffemodel\", caffemodel,\n",
    "                    \"--net_name\", name,\n",
    "                    \"--output_dir\", \"work\",\n",
    "                    \"--arch\", \"/opt/vitis_ai/compiler/arch/dpuv1/ALVEO/ALVEO.json\",\n",
    "                    \"--options\", \"{\\\"quant_cfgfile\\\":\\\"%s\\\", \\\n",
    "                    \\\"pipelineconvmaxpool\\\":False, \\\n",
    "                    }\" %(quantize_info)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the Subgraph Cutter\n",
    "\n",
    "The subgraph cutter creates a custom python layer to be accelerated on the FPGA. The inputs are compiler.json, quantizer.json and model weights from the compiler step, as well as the FPGA xclbin. This outputs a cut prototxt file with FPGA references, to be used for inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cut(prototxt):\n",
    "    \n",
    "    cutter = xfdnnCutter(\n",
    "        inproto=\"quantize_results/deploy.prototxt\",\n",
    "        trainproto=prototxt,\n",
    "        outproto=\"xfdnn_auto_cut_deploy.prototxt\",\n",
    "        outtrainproto=\"xfdnn_auto_cut_train_val.prototxt\",\n",
    "        cutAfter=\"data\",\n",
    "        xclbin=\"/opt/xilinx/overlaybins/xdnnv3\",\n",
    "        netcfg=\"work/compiler.json\",\n",
    "        quantizecfg=\"work/quantizer.json\",\n",
    "        weights=\"work/weights.h5\"\n",
    "    )\n",
    "    \n",
    "    cutter.cut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cut(prototxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Inference \n",
    "\n",
    "The inputs are the FPGA prototxt file, caffemodel weights, a test image, and the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from run_ssd import declare_network as network\n",
    "from run_ssd import Detect\n",
    "config = {}\n",
    "#auto_cut prototxt generated by subgraph in step-4\n",
    "config['prototxt'] = \"xfdnn_auto_cut_deploy.prototxt\" \n",
    "config['caffemodel'] = \"quantize_results/deploy.caffemodel\"\n",
    "config['labelmap_file'] = VAI_ALVEO_ROOT + \"/examples/caffe/ssd-detect/labelmap_voc_19c.prototxt\"\n",
    "config['image'] = VAI_ALVEO_ROOT + \"/examples/caffe/ssd-detect/Yogi.jpeg\"\n",
    "config['img_mean']= [104,117,123]\n",
    "config['img_input_scale'] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose image to run, display it for reference\n",
    "image = config['image']\n",
    "display(filename=image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Detect(\"xfdnn_auto_cut_deploy.prototxt\", config[\"caffemodel\"], config[\"image\"], config[\"labelmap_file\"], config)\n",
    "display(filename='res_det.jpg') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This notebook demonstrates how to target Xilinx FPGAs for inference using Caffe.  \n",
    "When the time comes to take your application to production please look at examples in /workspace/ml-suite/examples/deployment_modes/  \n",
    "Highest performance is acheived by creating multiprocess pipelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
