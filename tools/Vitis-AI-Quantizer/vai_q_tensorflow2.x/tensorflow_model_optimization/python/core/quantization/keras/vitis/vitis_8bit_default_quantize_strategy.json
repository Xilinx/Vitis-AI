{
  "input_quantizer":
  {
    "quantizer_type": "LastValueQuantPosQuantizer",
    "quantizer_params": {"bit_width": 8, "method": 0, "round_mode": 1}
  },

  "quantize_strategies":
  [
    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "Conv2D",
      "quantizable_weights": ["kernel", "bias"],
      "weight_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 0}
        },
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 0}
        }
      ],
      "quantizable_activations": ["activation"],
      "activation_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ],
      "quantizable_outputs": [],
      "output_quantizers": []
    },

    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "DepthwiseConv2D",
      "quantizable_weights": ["depthwise_kernel", "bias"],
      "weight_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 0}
        },
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 0}
        }
      ],
      "quantizable_activations": ["activation"],
      "activation_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ],
      "quantizable_outputs": [],
      "output_quantizers": []
    },

    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "Conv2DTranspose",
      "quantizable_weights": ["kernel", "bias"],
      "weight_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 0}
        },
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 0}
        }
      ],
      "quantizable_activations": ["activation"],
      "activation_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ],
      "quantizable_outputs": [],
      "output_quantizers": []
    },
    
    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "Dense",
      "quantizable_weights": ["kernel", "bias"],
      "weight_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 0}
        },
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 0}
        }
      ],
      "quantizable_activations": ["activation"],
      "activation_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ],
      "quantizable_outputs": [],
      "output_quantizers": []
    },

    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "Activation",
      "quantizable_weights": [],
      "weight_quantizers": [],
      "quantizable_activations": ["activation"],
      "activation_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ],
      "quantizable_outputs": [],
      "output_quantizers": []
    },

    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "ReLU",
      "quantizable_weights": [],
      "weight_quantizers": [],
      "quantizable_activations": [],
      "activation_quantizers": [],
      "quantizable_outputs": [0],
      "output_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ]
    },

    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "ZeroPadding2D",
      "quantizable_weights": [],
      "weight_quantizers": [],
      "quantizable_activations": [],
      "activation_quantizers": [],
      "quantizable_outputs": [0],
      "output_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ]
    },

    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "Add",
      "quantizable_weights": [],
      "weight_quantizers": [],
      "quantizable_activations": [],
      "activation_quantizers": [],
      "quantizable_outputs": [0],
      "output_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ]
    },

    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "BatchNormalization",
      "quantizable_weights": ["gamma", "beta"],
      "weight_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 0}
        },
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 0}
        }
      ],
      "quantizable_activations": [],
      "activation_quantizers": [],
      "quantizable_outputs": [0],
      "output_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ]
    },

    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "MaxPooling2D",
      "quantizable_weights": [],
      "weight_quantizers": [],
      "quantizable_activations": [],
      "activation_quantizers": [],
      "quantizable_outputs": [0],
      "output_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ]
    },

    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "AveragePooling2D",
      "quantizable_weights": [],
      "weight_quantizers": [],
      "quantizable_activations": [],
      "activation_quantizers": [],
      "quantizable_outputs": [0],
      "output_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ]
    },

    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "GlobalAveragePooling2D",
      "quantizable_weights": [],
      "weight_quantizers": [],
      "quantizable_activations": [],
      "activation_quantizers": [],
      "quantizable_outputs": [0],
      "output_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ]
    },

    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "UpSampling2D",
      "quantizable_weights": [],
      "weight_quantizers": [],
      "quantizable_activations": [],
      "activation_quantizers": [],
      "quantizable_outputs": [0],
      "output_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ]
    },

    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "Concatenate",
      "quantizable_weights": [],
      "weight_quantizers": [],
      "quantizable_activations": [],
      "activation_quantizers": [],
      "quantizable_outputs": [0],
      "output_quantizers": [
        {
          "quantizer_type": "LastValueQuantPosQuantizer",
          "quantizer_params": {"bit_width": 8, "method": 1, "round_mode": 1}
        }
      ]
    },

    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "Reshape",
      "quantizable_weights": [],
      "weight_quantizers": [],
      "quantizable_activations": [],
      "activation_quantizers": [],
      "quantizable_outputs": [],
      "output_quantizers": []
    },
    
    {
      "layer_module": "tensorflow.keras.layers",
      "layer_type": "Flatten",
      "quantizable_weights": [],
      "weight_quantizers": [],
      "quantizable_activations": [],
      "activation_quantizers": [],
      "quantizable_outputs": [],
      "output_quantizers": []
    }
  ]
}
