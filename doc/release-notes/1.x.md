# Vitis AI Release Notes

## Release 1.1

### New Features

#### Model Zoo
	
* Model quantization accuracy update
* Model test and retraining improved
* Caffe_Xilinx updated to version 1.1
* U50, U200, U250 performance added

#### Quantizer

* Add Tensorflow 1.15 support
* Bugfixes

#### Compiler

* Support cross compilation for Zynq and ZU+ based platforms 
* Vitis AI Compiler for U50
    -	Based on the new XIR (Xilinx Intermediate Representation)
    -	Support DPUv3E
    -   Tested with 40 models from Vitis AI Model Zoo
* Vitis AI Compiler for Zynq and ZU+
    -   Support DPUv2 1.4.1 instruction set
    -   Support bias rightward-shift computation to improve model accuracy
    -   Support bilinear upsampling operator

#### Runtime

* VART (Vitis AI Runtime) 
    -   Unified runtime based on XIR for Zynq, ZU+ and Alveo
    -   Include new APIs for NN performance improvement
    -   7 samples with VART APIs provided


#### DPU

*  DPUv2 for Zynq and ZU+
*  DPUv2
    -  Upgrade to version 1.4.1
    -  DPU TRD update with Vitis 2019.2 and Vitis AI Library 1.1
*  DPUv3E
    -  https://github.com/Xilinx/Vitis-AI/tree/master/alveo-hbm
    
#### Vitis AI Library

* All source code open source
* Support VART
* Add support for Alveo
* Support batch model for DPUv3E 

#### Example & Demo

* Whole Application Acceleration Example
* End-to-end pipeline which includes JPEG decode, Resize, CNN inference on Alveo
* Neptune demo: Use FPGA for multi-stream and multi-model mode
* AKS demo: Building complex application using C++ and threads

#### Others

* TVM (Early access, provide docker upon request)
    -  Supported frontends: TFLite, ONNX, MxNet and Pytorch
    -  Platform support: ZCU102, ZC104, U200 and U250
    -  Tested for 15 models including classification, detection and segmentation from various frameworks
* xButler upgraded to version 3.0 and provides support for docker container.
* Improved support on upsampling, deconvolution and large convolutions for segmentation models including FPN for DPUv1

### Known Issues
* Alveo U50 toolchain doesn't support Conv2DTranspose trained in Keras and converted to TF 1.15, which will be fixed in Vitis AI 1.2 release. 

### Updates 
* 5/6/20 - Fixed hardware bug which will lead to computation errors in some corner case for Alveo U50 Production shell xclbin. 
* 5/6/20 - Added support for Alveo U50 using EA x4 shell for increased performance. 

<br />



<br />

## Release 1.0

### New Features

#### Model Zoo
	
* Release custom Caffe framework distribution caffe_xilinx
* Add accuracy test code and retrain code for all Caffe models
* Increase Tensorflow models to 19 with float/fixed model versions and accuracy test code, including popular models such as SSD, YOLOv3, MLPerf:ssd_resnet34, etc.
* Add multi-task Caffe model for ADAS applications


#### Optimizer (A separate package which requires licensing)

*  Caffe Pruning
    - Support for depthwise convolution layer
    - Remove internal implementation-related parameters in transformed prototxt
*  TensorFlow Pruning
    -   Release pruning tool based on TensorFlow 1.12
    -   Add more validations to user-specified parameters
    -   Bug fixes for supporting more networks
*  Darknet pruning
    -	new interface for pruning tool
    -	support yolov3-spp

#### Quantizer

*  Tensorflow quantization
    -	Support DPU simulation and dumping quantize simulation results.
    -	Improve support for some layers and node patterns, including tf.keras.layers.Conv2DTranspose, tf.keras.Dense, tf.keras.layers.LeakyReLU, tf.conv2d + tf.mul 
    -	Move temp quantize info files from /tmp/ to $output_dir/temp folder, to support multi-users on one machine
    -	Bugfixes
	
*  Caffe quantization
    -	Enhanced activation data dump function
    -	Ubuntu 18 support
    -	Non-unified bit width quantization support
    -	Support HDF5 data layer
    -	Support of scale layers without parameters but with multiple inputs

#### Compiler
* Support cross compilation for Zynq and ZU+ based platforms 
* Enhancements and bug fixes for a broader set of Tensorflow models
* New Split IO memory model enablement for performance optimization 
* Improved code generation
* Support Caffe/TensorFlow model compilation over cloud DPU V3E (Early Access)


#### Runtime
* Enable edge to cloud deployment over XRT 2019.2
* Offer the unified Vitis AI C++/Python programming APIs
* DPU priority-based scheduling and DPU core affinity
* Introduce adaptive operating layer to unify runtime’s underlying interface for Linux, XRT and QNX
* QNX RTOS enablement to support automotive customers.
* Neptune API for X+ML
* Performance improvements


#### DPU

*  	DPUv2 for Zynq and ZU+
    -	Support Vitis flow with reference design based on ZCU102
    -	The same DPU also supports Vivado flow
    -	All features are configurable
    -	Fixed several bugs

*  DPUv3 for U50/U280 (Early access)

#### Vitis AI Library

* Support of new Vitis AI Runtime - Vitis AI Library is updated to be based on the new Vitis AI Runtime with unified APIs. It also fully supports XRT 2019.2.
* New DPU support - Besides DPUv2 for Zynq and ZU+, a new AI Library will support new DPUv3 IPs for Alveo/Cloud using same codes (Early access). 
* New Tensorflow model support - There are up to 19 tensorflow models supported, which are from official tensorflow repository
* New libraries and demos - There are two new libraries “libdpmultitask” and “libdptfssd” which supports multi-task models and Tensorflow SSD models. An updated classification demo is included to shows how to uses unified APIs in Vitis AI runtime.
* New Open Source Library - The “libdpbase” library is open source in this release, which shows how to use unified APIs in Vitis AI runtime to construct high-level libraries.
* New Installation Method - The host side environment adopts uses image installation, which simplifies and unifies the installation process.


#### Others
* Support for TVM which enables support for Pytorch, ONNX and SageMaker NEO
* Partitioning of Tensorflow models and support for xDNNv3 execution in Tensorflow natively
* Automated Tensorflow model partition, compilation and deployment over DPUv3 (Early access)
* Butler API for following:
    -	Automatic resource discovery and management
    -	Multiprocess support – Ability for many containers/processes to access single FPGA
    -	FPGA slicing – Ability to use part of FPGA
    -	Scaleout support for multiple FPGA on same server
* Support for pix2pix models

### Known Issues

